{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data + checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin          77.104377\n",
       "Age            19.865320\n",
       "Embarked        0.224467\n",
       "Fare            0.000000\n",
       "Ticket          0.000000\n",
       "Parch           0.000000\n",
       "SibSp           0.000000\n",
       "Sex             0.000000\n",
       "Name            0.000000\n",
       "Pclass          0.000000\n",
       "Survived        0.000000\n",
       "PassengerId     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "missing = df.isnull().sum()/df.isnull().count()*100\n",
    "missing_data_columns = missing.index[missing!=0]\n",
    "missing.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore & filling columns with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age Cabin Embarked\n",
      "0  22.0   NaN        S\n",
      "1  38.0   C85        C\n",
      "2  26.0   NaN        S\n",
      "3  35.0  C123        S\n",
      "4  35.0   NaN        S\n"
     ]
    }
   ],
   "source": [
    "df_missing = df[missing_data_columns]\n",
    "print(df_missing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = #FFF8C6> Cabin has too many missing data and it is a string with countless possibilities, impossible for us to fill data in meaningful way, drop from dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.699118\n",
       "std       14.526497\n",
       "min        0.420000\n",
       "25%       20.125000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing['Age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling ages column according to mean of each salutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups passengers by salutations\n",
    "df['Salutation'] = df['Name'].apply(lambda name: name.split(',')[1].split('.')[0])\n",
    "# fill missing ages with mean of salutations note: x in lambda refers to the group!\n",
    "df['Age'] = df.groupby('Salutation')['Age'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning ages, to see if it helps prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAARl0lEQVR4nO3df4xlZ13H8feHLgUCyPbHuDa7q0t0BesPSplgEVRowdCi7BqhtiF2rWtWTRWIP1f9A0hMLDGx0GhqNrS6RYTWYtNNqWjd0mjRFqa0VNuCHWqb3bXtjhXKjwJa+PrHfVZutzM7d2buzHSffb+Sm/uc53nOOc/dM/O55z5zzt1UFZKkvjxjtQcgSRo/w12SOmS4S1KHDHdJ6pDhLkkdWrPaAwA4+eSTa9OmTas9DEk6qtx+++3/VVUTs7U9LcJ906ZNTE1NrfYwJOmokuTBudqclpGkDs0b7klelOTOoccXk7w9yYlJbkxyX3s+ofVPkkuTTCe5K8npy/8yJEnD5g33qvpsVZ1WVacBLwMeB64FdgJ7q2ozsLctA5wNbG6PHcBlyzFwSdLcFjotcxbwuap6ENgC7G71u4GtrbwFuLIGbgXWJjllLKOVJI1koeF+HvDBVl5XVQ+18sPAulZeD+wbWmd/q3uSJDuSTCWZmpmZWeAwJElHMnK4JzkeeCPw14e31eDbxxb0DWRVtauqJqtqcmJi1it5JEmLtJAz97OBT1XVI235kUPTLe35YKs/AGwcWm9Dq5MkrZCFhPv5fGtKBmAPsK2VtwHXDdVf0K6aOQN4bGj6RpK0Aka6iSnJc4HXAb80VH0xcHWS7cCDwLmt/gbgHGCawZU1F45ttJKkkYwU7lX1FeCkw+oeZXD1zOF9C7hoLKMbwaadH1mpXR1zHrj4Das9BEmL5B2qktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0aKdyTrE1yTZLPJLk3ySuSnJjkxiT3tecTWt8kuTTJdJK7kpy+vC9BknS4Uc/c3wt8tKpeDLwEuBfYCeytqs3A3rYMcDawuT12AJeNdcSSpHnNG+5JXgD8GHA5QFX9T1V9AdgC7G7ddgNbW3kLcGUN3AqsTXLK2EcuSZrTKGfuLwRmgD9PckeS9yV5LrCuqh5qfR4G1rXyemDf0Pr7W92TJNmRZCrJ1MzMzOJfgSTpKUYJ9zXA6cBlVfVS4Ct8awoGgKoqoBay46raVVWTVTU5MTGxkFUlSfMYJdz3A/ur6ra2fA2DsH/k0HRLez7Y2g8AG4fW39DqJEkrZN5wr6qHgX1JXtSqzgLuAfYA21rdNuC6Vt4DXNCumjkDeGxo+kaStALWjNjv14APJDkeuB+4kMEbw9VJtgMPAue2vjcA5wDTwOOtryRpBY0U7lV1JzA5S9NZs/Qt4KIljkuStATeoSpJHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUoZHCPckDSf41yZ1JplrdiUluTHJfez6h1SfJpUmmk9yV5PTlfAGSpKdayJn7a6rqtKqabMs7gb1VtRnY25YBzgY2t8cO4LJxDVaSNJqlTMtsAXa38m5g61D9lTVwK7A2ySlL2I8kaYFGDfcC/j7J7Ul2tLp1VfVQKz8MrGvl9cC+oXX3t7onSbIjyVSSqZmZmUUMXZI0lzUj9ntVVR1I8u3AjUk+M9xYVZWkFrLjqtoF7AKYnJxc0LqSpCMb6cy9qg6054PAtcDLgUcOTbe054Ot+wFg49DqG1qdJGmFzBvuSZ6b5PmHysBPAP8G7AG2tW7bgOtaeQ9wQbtq5gzgsaHpG0nSChhlWmYdcG2SQ/3/qqo+muSTwNVJtgMPAue2/jcA5wDTwOPAhWMftSTpiOYN96q6H3jJLPWPAmfNUl/ARWMZnSRpUbxDVZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdWjkcE9yXJI7klzfll+Y5LYk00muSnJ8q39WW55u7ZuWZ+iSpLks5Mz9bcC9Q8vvBi6pqu8BPg9sb/Xbgc+3+ktaP0nSChop3JNsAN4AvK8tBzgTuKZ12Q1sbeUtbZnWflbrL0laIaOeub8H+G3gm235JOALVfVEW94PrG/l9cA+gNb+WOv/JEl2JJlKMjUzM7PI4UuSZjNvuCf5SeBgVd0+zh1X1a6qmqyqyYmJiXFuWpKOeWtG6PNK4I1JzgGeDXwb8F5gbZI17ex8A3Cg9T8AbAT2J1kDvAB4dOwjlyTNad4z96r63araUFWbgPOAm6rqLcDHgDe1btuA61p5T1umtd9UVTXWUUuSjmgp17n/DvDrSaYZzKlf3uovB05q9b8O7FzaECVJCzXKtMz/q6qbgZtb+X7g5bP0+Rrw5jGMTZK0SN6hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktShecM9ybOTfCLJp5PcneRdrf6FSW5LMp3kqiTHt/pnteXp1r5peV+CJOlwo5y5fx04s6peApwGvD7JGcC7gUuq6nuAzwPbW//twOdb/SWtnyRpBc0b7jXw5bb4zPYo4Ezgmla/G9jaylvaMq39rCQZ24glSfMaac49yXFJ7gQOAjcCnwO+UFVPtC77gfWtvB7YB9DaHwNOmmWbO5JMJZmamZlZ2quQJD3JSOFeVd+oqtOADcDLgRcvdcdVtauqJqtqcmJiYqmbkyQNWdDVMlX1BeBjwCuAtUnWtKYNwIFWPgBsBGjtLwAeHctoJUkjGeVqmYkka1v5OcDrgHsZhPybWrdtwHWtvKct09pvqqoa56AlSUe2Zv4unALsTnIcgzeDq6vq+iT3AB9K8gfAHcDlrf/lwPuTTAP/DZy3DOOWJB3BvOFeVXcBL52l/n4G8++H138NePNYRidJWhTvUJWkDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0LzhnmRjko8luSfJ3Une1upPTHJjkvva8wmtPkkuTTKd5K4kpy/3i5AkPdkoZ+5PAL9RVacCZwAXJTkV2AnsrarNwN62DHA2sLk9dgCXjX3UkqQjmjfcq+qhqvpUK38JuBdYD2wBdrduu4GtrbwFuLIGbgXWJjll7COXJM1pQXPuSTYBLwVuA9ZV1UOt6WFgXSuvB/YNrba/1R2+rR1JppJMzczMLHDYkqQjGTnckzwP+DDw9qr64nBbVRVQC9lxVe2qqsmqmpyYmFjIqpKkeYwU7kmeySDYP1BVf9OqHzk03dKeD7b6A8DGodU3tDpJ0goZ5WqZAJcD91bVHw817QG2tfI24Lqh+gvaVTNnAI8NTd9IklbAmhH6vBL4OeBfk9zZ6n4PuBi4Osl24EHg3NZ2A3AOMA08Dlw41hFLkuY1b7hX1S1A5mg+a5b+BVy0xHFJkpbAO1QlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1KFRvhVSGqtNOz+y2kPo1gMXv2G1h6CnCc/cJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR2aN9yTXJHkYJJ/G6o7McmNSe5rzye0+iS5NMl0kruSnL6cg5ckzW6UM/e/AF5/WN1OYG9VbQb2tmWAs4HN7bEDuGw8w5QkLcS84V5V/wj892HVW4Ddrbwb2DpUf2UN3AqsTXLKuAYrSRrNYufc11XVQ638MLCuldcD+4b67W91kqQVtOQ/qFZVAbXQ9ZLsSDKVZGpmZmapw5AkDVlsuD9yaLqlPR9s9QeAjUP9NrS6p6iqXVU1WVWTExMTixyGJGk2iw33PcC2Vt4GXDdUf0G7auYM4LGh6RtJ0gqZ9/vck3wQeDVwcpL9wDuAi4Grk2wHHgTObd1vAM4BpoHHgQuXYcySpHnMG+5Vdf4cTWfN0reAi5Y6KEnS0niHqiR1yHCXpA4Z7pLUIcNdkjpkuEtSh+a9WkaSNu38yGoPoVsPXPyGZdmuZ+6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4tS7gneX2SzyaZTrJzOfYhSZrb2MM9yXHAnwJnA6cC5yc5ddz7kSTNbTnO3F8OTFfV/VX1P8CHgC3LsB9J0hyW4/9QXQ/sG1reD/zw4Z2S7AB2tMUvJ/nsMozl6ehk4L9WexCjyLtXewRPC0fN8QKPWXMsHbPvmqth1f6D7KraBexarf2vliRTVTW52uPQaDxeRx+P2cByTMscADYOLW9odZKkFbIc4f5JYHOSFyY5HjgP2LMM+5EkzWHs0zJV9USSXwX+DjgOuKKq7h73fo5ix9xU1FHO43X08ZgBqarVHoMkacy8Q1WSOmS4S1KHDPcxSLI1SSV58Rztf5HkTfNs4+eT/MnQ9ryrd5GSfEeSDyX5XJLbk9yQZEeS6+fo/75D/95JHkhy8ix93pnkN5d77IIk30hy59BjZ6u/OclTLnEc/t1ZwD5ePdfPQy9W7Tr3zpwP3NKe3zGG7W0FrgfuGcO2jilJAlwL7K6q81rdS4A3zrVOVf3iEva3pqqeWOz6mtVXq+q05dp4kmMi9zxzX6IkzwNeBWxncNknGfiT9uVp/wB8+1D//z8zTDKZ5ObDtvcjDILoj9pZy3ev0EvpxWuA/62qPztUUVWfBv4JeF6Sa5J8JskH2hvBkc4Ifz/Jvye5BXjRUP3NSd6TZAp4W5KJJB9O8sn2eGXr984kV7T+9yd56zK/9mNGkgvbsfkE8Mqh+iMdi/cn+Tjw/qH+z0hyX5KJoeXpQ8tHs2PiHWyZbQE+WlX/nuTRJC9jcEvwixh8cdo6BmfgV4yysar65yR7gOur6prlGnTHfgC4fY62lwLfD/wn8HEGoXDLbB3bcTwPOI3B78mnDtvu8YfugkzyV8AlVXVLku9kcBnw97V+L2bwhvN84LNJLquq/138yzsmPCfJnUPLf1hVVx1aSHIK8C7gZcBjwMeAO1rze5n7WJwKvKqqvprk1QBV9c0kfwm8BXgP8Frg01U1s2yvboUY7kt3PoMfKBh8Sdr5DP5dP1hV3wD+M8lNqzU4Pcknqmo/QAuPTcwR7sCPAtdW1eOt/+E34l01VH4tcGr7IADwbe0THcBHqurrwNeTHGTwZr9/qS+kc/NNy/wwcPOhAE5yFfC9re1Ix2JPVX11lu1dAVzHINx/AfjzJY7/acFwX4IkJwJnAj+YpBjctFUM5nzn8gTfmg579vKO8Jh0NzDXH6+/PlT+Bkv7+f/KUPkZwBlV9bXhDi1gxrlPze9Ix+Irs61QVfuSPJLkTAbfavuWZR/lCnDOfWneBLy/qr6rqjZV1UbgP4BHgZ9Nclz7CPmaoXUeYPBxEuBn5tjulxh8jNfC3QQ8K4NvHQUgyQ8xOBNfiH8EtiZ5TpLnAz91hL5/D/za0P6W7Y+BAuA24MeTnJTkmcCbh9oWeyzeB/wl8NftE/dRz3BfmvN56ln6h4FTgPsYzLVfCfzLUPu7gPe2P8bN9UP0IeC3ktzhH1QXpga3XP808Np2KeTdwB8CDy9wO59iMPXyaeBvGXxn0lzeCkwmuSvJPcAvL2rwOuQ5h10KefFwY1U9BLyTwe/Vx4F7h5oXeyz2AM+jkykZ8OsHJIl2tdQlVbXQT3hPW87/STqmtZukfoVO5toP8cxdkjrknLskdchwl6QOGe6S1CHDXZI6ZLhLUof+D8Tte9ZG1myAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_labels = ['Children','Adult','Elderly']\n",
    "df['Age_group']=pd.cut(df['Age'], [0,18,50,df['Age'].max()], labels = age_labels)\n",
    "plt.bar(df['Age_group'].value_counts().index,df['Age_group'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill embarked with mode of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'].fillna(str(df.Embarked.mode()), inplace = True)\n",
    "#df.Embarked.mode() is a Series, need to be converted to string, quite silly, really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "Salutation       0\n",
       "Age_group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "#All filled up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping useless features and converting Pclass to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_useful = df.drop(columns = ['PassengerId','Name','Cabin','Ticket','Salutation','Parch','SibSp','Age'])\n",
    "df_useful['Pclass'] = df_useful['Pclass'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binaried = pd.get_dummies(df_useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binaried.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting heatmap of correlation, just for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_binaried.corr()\n",
    "sns.heatmap(abs(corr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(corr['Survived']).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making and tuning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making an SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_binaried.loc[:,df_binaried.columns != 'Survived']\n",
    "y = df_binaried['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "for g in np.logspace(-4,1,6):\n",
    "    clf = SVC(kernel = 'rbf', gamma = g).fit(X_train, y_train)\n",
    "    print('Gamma value:',g)\n",
    "    print('Test score: {:.2f}'.format(clf.score(X_test,y_test)))\n",
    "    print('Train score: {:.2f}'.format(clf.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "for g in np.logspace(-4,1,6):\n",
    "    clf = SVC(kernel = 'rbf', gamma = g).fit(X_train_scaled, y_train)\n",
    "    print('Gamma value:',g)\n",
    "    print('Test score: {:.2f}'.format(clf.score(X_test_scaled,y_test)))\n",
    "    print('Train score: {:.2f}'.format(clf.score(X_train_scaled,y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curve without feature normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "train_scores, valid_scores = validation_curve(SVC(kernel = 'rbf'), X, y, \"gamma\", \n",
    "                                                  np.logspace(-4,1,6), cv = 3)\n",
    "cv_scores = np.mean(train_scores, axis = 1),np.mean(valid_scores, axis = 1)\n",
    "pd.DataFrame(cv_scores, index = ['Train scores','Test scores'], columns =np.logspace(-4,1,6) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curve after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(X)\n",
    "scaled_train_scores, scaled_valid_scores = validation_curve(SVC(kernel = 'rbf'), X_scaled, y, \"gamma\", \n",
    "                                                  np.logspace(-4,2,7), cv = 3)\n",
    "scaled_cv_scores = np.mean(scaled_train_scores, axis = 1),np.mean(scaled_valid_scores, axis = 1)\n",
    "pd.DataFrame(scaled_cv_scores, index = ['Train scores','Test scores'], columns =np.logspace(-4,2,7) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "for this_c in [0.0001,0.001,.01,.1,1,10,100]:\n",
    "    lg_clf = LogisticRegression(C = this_c, solver = 'liblinear').fit(X_train_scaled, y_train)\n",
    "    print('C = {}, train score: {:.2f}'.format(this_c,lg_clf.score(X_train_scaled,y_train)))\n",
    "    print('C = {}, test score: {:.2f}'.format(this_c,lg_clf.score(X_test_scaled,y_test)))\n",
    "# increase in C, increases in fitting of model to train data (more overfitting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating model with full training set\n",
    "Just for simplicity, I have chosen a logistic regression model with C = 0.01, I will return to the model selection step when I know of better ways to select models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(X)\n",
    "chosen_model = LogisticRegression(C = 0.01, solver = 'liblinear').fit(X_scaled,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data will need filling: Age column and fare, I shall do both with mean, out of laziness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Fare'].fillna(df_test.Fare.mean(), inplace = True)\n",
    "df_test['Age'].fillna(df_test.Age.mean(), inplace = True)\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_selected = df_test.drop(columns = ['PassengerId','Name','Cabin','Ticket','Parch','SibSp'])\n",
    "df_test_selected['Pclass'] = df_useful['Pclass'].astype(str)\n",
    "df_test_processed = pd.get_dummies(df_test_selected)\n",
    "df_test_scaled = scaler.fit_transform(df_test_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making prediction on test data and generating CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.Series(chosen_model.predict(df_test_scaled), name = 'Survived')\n",
    "df_answer = pd.concat([df_test['PassengerId'],answer], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer.to_csv(r'/Users/jansen/documents/dspractice/kaggle/titanic_answer.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SVC(kernel = 'rbf', gamma = 10).fit(X_scaled, y)\n",
    "answer2 = pd.Series(model2.predict(df_test_scaled), name = 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerSVC = pd.concat([df_test['PassengerId'],answer2], axis = 1)\n",
    "answerSVC.to_csv(r'/Users/jansen/documents/dspractice/kaggle/titanic_answer_SVC.csv',index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
